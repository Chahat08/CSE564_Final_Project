{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencage.geocoder import OpenCageGeocode\n",
    "from opencage.geocoder import InvalidInputError, RateLimitExceededError, UnknownError\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = '2c67f66fd0cd44cdacf36b54154b9cdf'\n",
    "# key = '90f7c1eb939440d2b00dea098f80d76d'\n",
    "key = 'ded082443a7c41e689f5914b123889be'\n",
    "geocoder = OpenCageGeocode(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/eclipse_data_enriched_5000_years.csv\")\n",
    "df = pd.read_csv(\"data/geo_coded_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_geocode(row):  \n",
    "    latitude = row['Eclipse Latitude']\n",
    "    longitude = row['Eclipse Longitude'] \n",
    "    try:\n",
    "        results = geocoder.reverse_geocode(latitude, longitude)\n",
    "        if results and len(results):\n",
    "            return get_location(results)\n",
    "    except RateLimitExceededError as ex:\n",
    "        print(\"Rate Limit Error\")\n",
    "        return str(ex)\n",
    "    except InvalidInputError as ex:\n",
    "        print(\"Invalid Input Error\")\n",
    "        \n",
    "        return str(ex)\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "def get_location(results):\n",
    "    location = results[0]['components']\n",
    "\n",
    "    country_name = location.get('country', None)\n",
    "    alpha_2_code = location.get('ISO_3166-1_alpha-2', None)\n",
    "    alpha_3_code = location.get('ISO_3166-1_alpha-3', None)\n",
    "    \n",
    "    return country_name, alpha_2_code, alpha_3_code \n",
    "\n",
    "\n",
    "def update_csv(df, filename, batch_size=100):\n",
    "    for i in range(690, 2392, batch_size):\n",
    "        batch = df[i:i+batch_size]\n",
    "        batch['Country'], batch['Alpha2'], batch['Alpha3'] = zip(*batch.apply(reverse_geocode, axis=1))\n",
    "\n",
    "        batch.to_csv(filename, mode='a', header=not i, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_13744\\1993931186.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch['Country'], batch['Alpha2'], batch['Alpha3'] = zip(*batch.apply(reverse_geocode, axis=1))\n"
     ]
    }
   ],
   "source": [
    "update_csv(df, 'data/geo_coded_data2.csv', batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_country = pd.read_csv(\"data/geo_coded_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_country.to_csv(\"data/geo_coded_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE JSON WITH COUNTRY NAME TO ALPHA3 CODE MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "with open('data/world.geojson', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create a dictionary to store the mapping\n",
    "country_mapping = {}\n",
    "\n",
    "# Iterate through the features\n",
    "for feature in data['features']:\n",
    "    country_name = feature['properties']['name']\n",
    "    country_id = feature['id']\n",
    "    country_mapping[country_name] = country_id\n",
    "\n",
    "# Write the mapping to a new JSON file\n",
    "with open('data/alpha3Codes.json', 'w') as f:\n",
    "    json.dump(country_mapping, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDING CODES TO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/geo_coded_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open(\"data/alpha3Codes.json\", \"r\") as f:\n",
    "    country_mapping = json.load(f)\n",
    "    \n",
    "\n",
    "# Function to get Alpha3Code\n",
    "def get_alpha3code(country_name):\n",
    "    alpha3code = country_mapping.get(country_name, \"NOT FOUND\")\n",
    "    if alpha3code == \"NOT FOUND\":\n",
    "        print(f\"Country not found: {country_name}\")\n",
    "    return alpha3code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Alpha3Code column\n",
    "data[\"Alpha3\"] = data[\"Country\"].apply(lambda x: get_alpha3code(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAN GEOCODED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/geo_coded_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Catalog Number                                  7545\n",
       "Calendar Date                           1172 June 23\n",
       "Eclipse Time                                04:47:38\n",
       "Delta T (s)                                      813\n",
       "Lunation Number                               -10235\n",
       "Saros Number                                      94\n",
       "Eclipse Type                                       P\n",
       "Gamma                                         1.1539\n",
       "Eclipse Magnitude                           0.647739\n",
       "Latitude                                       65.1N\n",
       "Longitude                                      90.0W\n",
       "Sun Altitude                                       0\n",
       "Sun Azimuth                                      340\n",
       "Path Width (km)                                  NaN\n",
       "Central Duration                                 NaN\n",
       "Date Time                               1172 June 23\n",
       "Year                                            1172\n",
       "Month                                              6\n",
       "Day                                               23\n",
       "Visibility                               Not Visible\n",
       "Eclipse Latitude                                65.1\n",
       "Eclipse Longitude                              -90.0\n",
       "obliquity                                  23.546684\n",
       "Geographical Hemisphere                          N W\n",
       "Daytime/Nighttime                          Nighttime\n",
       "Sun Constellation                             Gemini\n",
       "Inter-Eclipse Duration                           148\n",
       "Visibility Score                             0.02303\n",
       "Eclipse Classification             Partial from Edge\n",
       "Duration in Seconds                              NaN\n",
       "Moon Distance (km)                     409989.024176\n",
       "Sun Distance (km)                   152124870.687003\n",
       "Moon Angular Diameter (degrees)             0.485599\n",
       "Sun Angular Diameter (degrees)              0.523898\n",
       "Central Duration Seconds                         NaN\n",
       "Normalized Duration                              NaN\n",
       "Normalized Path Width                            NaN\n",
       "EII                                              NaN\n",
       "Year Modulus                                    1172\n",
       "HEAS                                        0.609333\n",
       "Decade                                          1170\n",
       "Localized ESC                               1.906666\n",
       "ESC Moving Average                          1.739111\n",
       "ESC Wide-Scale Moving Average               1.860972\n",
       "Eclipse Interval                            0.472222\n",
       "Cluster                                            4\n",
       "Cluster 6                                          1\n",
       "Country                                       Canada\n",
       "Alpha2                                            CA\n",
       "Alpha3                                           CAN\n",
       "Name: 2488, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[2488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"data/geo_coded_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data, data2.iloc[2490:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3889"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/geocoded_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already read both DataFrames 'geodata' and 'geodataclean'\n",
    "geodata = pd.read_csv('./data/geo_coded_data.csv')\n",
    "geodataclean = pd.read_csv('./data/geo_coded_data_clean.csv')\n",
    "\n",
    "# Iterate through rows of geodataclean\n",
    "for index, row in geodataclean.iterrows():\n",
    "    # Get the Catalogue Number for the current row\n",
    "    catalogue_number = row['Catalog Number']\n",
    "    \n",
    "    # Locate the row in geodata with the same Catalogue Number\n",
    "    matching_row_index = geodata.index[geodata['Catalog Number'] == catalogue_number].tolist()\n",
    "    \n",
    "    # If a matching row is found, replace it with the current row from geodataclean\n",
    "    if matching_row_index:\n",
    "        geodata.iloc[matching_row_index[0]] = row\n",
    "\n",
    "# Now geodata should have the updated rows replaced from geodataclean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3889"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodata['Alpha3'].notna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata.to_csv(\"geodata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Read the GeoJSON file\n",
    "world_geojson = gpd.read_file('./data/world.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the GeoJSON file\n",
    "with open('./data/world.geojson', 'r') as f:\n",
    "    geojson_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon, LinearRing\n",
    "\n",
    "antarctica_rings = []\n",
    "for feature in geojson_data.get('features'):\n",
    "    if feature.get('id') == 'ATA':\n",
    "        antarctica_coords = (feature['geometry']['coordinates'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m lats_vect \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ring \u001b[38;5;129;01min\u001b[39;00m antarctica_coords:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lon, lat \u001b[38;5;129;01min\u001b[39;00m ring:\n\u001b[0;32m      5\u001b[0m         lons_vect\u001b[38;5;241m.\u001b[39mappend(lon)\n\u001b[0;32m      6\u001b[0m         lats_vect\u001b[38;5;241m.\u001b[39mappend(lat)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "lons_vect = []\n",
    "lats_vect = []\n",
    "for ring in antarctica_coords:\n",
    "    for ring2 in ring:\n",
    "        for lat, lon in ring2:\n",
    "            lons_vect.append(lon)\n",
    "            lats_vect.append(lat)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "lons_vect = np.array(lons_vect)\n",
    "lats_vect = np.array(lats_vect)\n",
    "\n",
    "# Stack longitude and latitude vectors vertically\n",
    "lons_lats_vect = np.column_stack((lons_vect, lats_vect))\n",
    "\n",
    "# Create a Polygon object\n",
    "polygon = Polygon(lons_lats_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/geodata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m eclipse_lon \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEclipse Longitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check if the coordinates are inside Antarctica\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_inside_antarctica\u001b[49m\u001b[43m(\u001b[49m\u001b[43meclipse_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meclipse_lon\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meclipse_lat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, longitude \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meclipse_lon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is inside Antarctica.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m, in \u001b[0;36mis_inside_antarctica\u001b[1;34m(lat, long)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_inside_antarctica\u001b[39m(lat, long):\n\u001b[0;32m     10\u001b[0m     point \u001b[38;5;241m=\u001b[39m Point(long, lat)\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mantarctica_boundary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m(point)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "        # Extract latitude and longitude from the row\n",
    "        eclipse_lat = row['Eclipse Latitude']\n",
    "        eclipse_lon = row['Eclipse Longitude']\n",
    "        \n",
    "        # Check if the coordinates are inside Antarctica\n",
    "        if is_inside_antarctica(eclipse_lat, eclipse_lon):\n",
    "            print(f\"latitude {eclipse_lat}, longitude {eclipse_lon} is inside Antarctica.\")\n",
    "        else:\n",
    "            print(f\"latitude {eclipse_lat}, longitude {eclipse_lon} is outside Antarctica.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
